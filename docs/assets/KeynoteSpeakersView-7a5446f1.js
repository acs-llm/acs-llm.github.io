import{b,d as v,a as p,u as _,e as y,o as s,c,n as u,f as t,r as w,g as f,h as S,i as P,w as A,j as a,F as C,k,t as l,l as d,m as D,_ as j}from"./index-778ce50a.js";const M=b({direction:{type:String,values:["horizontal","vertical"],default:"horizontal"},contentPosition:{type:String,values:["left","center","right"],default:"center"},borderStyle:{type:v(String),default:"solid"}}),U=p({name:"ElDivider"}),I=p({...U,props:M,setup(m){const o=m,n=_("divider"),r=y(()=>n.cssVar({"border-style":o.borderStyle}));return(e,g)=>(s(),c("div",{class:u([t(n).b(),t(n).m(e.direction)]),style:S(t(r)),role:"separator"},[e.$slots.default&&e.direction!=="vertical"?(s(),c("div",{key:0,class:u([t(n).e("text"),t(n).is(e.contentPosition)])},[w(e.$slots,"default")],2)):f("v-if",!0)],6))}});var L=P(I,[["__file","divider.vue"]]);const T=A(L);const N=""+new URL("Bingsheng He-5cce3933.jpg",import.meta.url).href,H=""+new URL("Heming Cui-8c07c797.jpg",import.meta.url).href,R=""+new URL("Hironori_Washizaki-273b1d6b.jpg",import.meta.url).href,B=""+new URL("Jun_Sun-331a2117.jpg",import.meta.url).href,E=""+new URL("Luo Mai-2b9c9731.jpg",import.meta.url).href,K=""+new URL("Marco Canini-3b1c497b.jpg",import.meta.url).href,G=""+new URL("Mohamed WAHIB-0b2556db.jpg",import.meta.url).href,x=""+new URL("Stefanos Kaxiras-15e5d149.jpg",import.meta.url).href,F=""+new URL("sun_jun-e84f040d.jpg",import.meta.url).href,z=""+new URL("globe-ec69cc7c.svg",import.meta.url).href,J=""+new URL("google-b60c38d2.svg",import.meta.url).href,O={class:"keynote-speakers"},W={class:"speaker-content"},V={class:"speaker-photo"},$=["src","alt"],q={class:"icon"},Y=["href"],Q=["href"],X={class:"speaker-info"},Z={class:"speaker-name"},ee={class:"bolder"},ae={class:"italic"},ie={class:"speaker-bio"},ne=p({__name:"KeynoteSpeakersView",setup(m){const o=[{name:"Stefanos Kaxiras, Uppsala University",photo:"Stefanos Kaxiras.jpg",title:"",keynote:"",abstract:"",bio:"",personalPage:"https://www.uu.se/en/contact-and-organisation/staff?query=N9-1645",academicPage:"https://scholar.google.com/citations?user=-FYgbQwAAAAJ&hl=en"},{name:"Bingsheng He, National University of Singapore",photo:"Bingsheng He.jpg",title:"",keynote:"",abstract:"",bio:"",personalPage:"https://www.comp.nus.edu.sg/~hebs/",academicPage:"https://scholar.google.com/citations?user=_S92MLYAAAAJ&hl=zh-CN"},{name:"Heming Cui, The University of Hong Kong",photo:"Heming Cui.jpg",title:"Building Four-dimensional Parallel Training Systems for Large AI Models",keynote:"",abstract:"The increasing modeling capacities of large DNNs (e.g., Transformer and GPT) have achieved unprecedented successes in various AI areas, including understanding vision and natural languages. The high modeling power a large DNN mainly stems from its increasing complexity (having more neuron layers and more neuron operators in each layer) and dynamicity (frequently activating/deactivating neuron operators in each layer during training, such as Neural Architecture Search, or NAS). Such complexity and dynamicity can easily make a large DNN exceed the computing and memory capacities of a modern GPU, so training a large DNN often often needs to split the DNN into many GPUs via multiple dimensions, including data parallelism, tensor parallelism, and pipeline parallelism. Dr. Cui’s talk will present his recent papers (e.g., [PipeMesh, in revision of a journal], [Fold3D TPDS 2023], [NASPipe ASPLOS 2022], and [vPipe TPDS 2021]), which address major limitations in existing multi-dimensional parallel training systems, including GPipe, Pipedream, and Megatron. For instance, vPipe focuses on addressing the severe load imbalance and low GPU computing utilization; NASPipe will present Supernet parallelism, a new parallel training dimension for highly dynamic large DNNs designed in the Supernet manners (e.g., Evolved Transformer and Neural Architecture Search). Fold3D is now the major thousands-GPU parallel training system on the world-renowned MindSpore AI framework.",bio:"Dr. Heming Cui (cs.hku.hk/people/academic-staff/heming) is an Associate Professor in HKU CS. Dr. Cui is interested in building software infrastructures and tools to greatly improve the reliability, security and performance of real-world software. After gaining his PhD degree in the Columbia University in 2015, he joined HKU and independently built a parallel and distributed system group with about 20 ongoing, full-time PhD students. His recent research has led to a series of open source projects and publications in international top conferences and journals of broad areas, including SOSP, IEEE S&P, VLDB, TPDS, MICRO, NSDI, ASPLOS, ATC, ICSE, EuroSys. In recent three years, Dr. Cui serves on the program committees for at least once of international top systems/networking conferences, including OSDI, SIGCOMM, ASPLOS, NSDI, ATC, and EuroSys. Dr. Cui received the ACM ICSE 2025 best paper award and the ACM ACSAC 2017 best paper award. He serves as the general chair of ACM APSys 2016 and 2021, and the program chair of ACM ChinaSys 2023. As a research project leader, his research projects have received a total fundings of about HKD $150 million, including the major fundings from Mainland China's National Key R&D Program (CNY $110 million), HK's Research Grants Council (e.g., the RGC Research Impact Fund in 2023), HK's Innovation & Technology Commission, and the Croucher Foundation. Dr. Cui's recent secure system papers (e.g., [Uranus AsiaCCS 2020] and [Cronus MICRO 2022]), and their resultant Ubiquitous Trusted Execution Environments (UTEE) project, have become the core commercial system of Huawei's Trusted and Intelligent Cloud Services (https://www.huaweicloud.com/product/tics.html) in 2021. Dr Cui’s parallel big AI model training systems (e.g., [Fold3D TPDS 2023], [NASPipe ASPLOS 2022], and [vPipe TPDS 2021]) are implemented on the PyTorch library and Nvidia’s GPUs with the support of general big AI models (e.g., Transformer, GPT, CPM, and Pan-Gu); Dr Cui’s Fold3D work is now the major thousands-GPU parallel training system on the world-renowned MindSpore AI framework. Dr Cui received his bachelor and master degrees from Tsinghua University, and PhD from Columbia University, all in Computer Science.",personalPage:"https://i.cs.hku.hk/~heming/",academicPage:"https://scholar.google.com/citations?user=lW9bpFIAAAAJ&hl=zh-CN"},{name:"Marco Canini, King Abdullah University of Science and Technology",photo:"Marco Canini.jpg",title:"Programmable Networks for Distributed Deep Learning: Advances and Perspectives",keynote:"",abstract:"",bio:"Marco does not know what the next big thing will be. He asked ChatGPT, though the answer was underwhelming. But he's sure that our future next-gen computing and networking infrastructure must be a viable platform for it. Marco's research spans a number of areas in computer systems, including distributed systems, large-scale/cloud computing and computer networking with emphasis on programmable networks. His current focus is on designing better systems support for AI/ML and providing practical implementations deployable in the real world. Marco is a Professor of Computer Science at KAUST. Marco obtained his Ph.D. in computer science and engineering from the University of Genoa in 2009 after spending the last year as a visiting student at the University of Cambridge. He was a postdoctoral researcher at EPFL and a senior research scientist at Deutsche Telekom Innovation Labs & TU Berlin. Before joining KAUST, he was an assistant professor at UCLouvain. He also held positions at Intel, Microsoft and Google.",personalPage:"https://mcanini.github.io/",academicPage:"https://scholar.google.com/citations?user=c-rwMUkAAAAJ&hl=zh-CN"},{name:"Mohamed WAHIB, RIKEN",photo:"Mohamed WAHIB.jpg",title:"Parallelism in LLMs: Beyond Data, Tensor, and Pipeline ParallelismParallelism in LLMs: Beyond Data, Tensor, and Pipeline Parallelism",keynote:"",abstract:"Large Language Models (LLMs) require enormous computational resources to train and deploy effectively. While techniques like data, tensor, and pipeline parallelism have become standard approaches to distribute this workload, the next frontier in parallelism promises to push the boundaries of model scalability and efficiency even further. This talk explores emerging methods and strategies for parallelism beyond the current paradigms, focusing on optimizing memory utilization, improving inter-node communication, and leveraging hardware advancements. We will also discuss the challenges of scaling LLMs and how future innovations in parallelism can unlock unprecedented performance gains.",bio:"Mohamed Wahib is a team leader of the “High Performance Artificial Intelligence Systems Research Team” at RIKEN Center for Computational Science (R-CCS), Kobe, Japan. Prior to that he worked as is a senior scientist at AIST/TokyoTech Open Innovation Laboratory, Tokyo, Japan. He received his Ph.D. in Computer Science from Hokkaido University, Japan. His research interests revolve around the central topic of high-performance programming systems, in the context of HPC and AI. He is actively working on several projects including AI-based science, as well as high-level frameworks for programming traditional scientific applications.",personalPage:"https://www.r-ccs.riken.jp/en/research/labs/hpaisrt/",academicPage:"https://scholar.google.com/citations?user=C3fmEegAAAAJ&hl=en"},{name:"Luo Mai, University of Edinburgh",photo:"Luo Mai.jpg",title:"",keynote:"",abstract:"",bio:"",personalPage:"https://luomai.github.io/",academicPage:"https://scholar.google.com/citations?user=I6GYccIAAAAJ&hl=en"}],n=r=>new URL(Object.assign({"../assets/image/photos/Bingsheng He.jpg":N,"../assets/image/photos/Heming Cui.jpg":H,"../assets/image/photos/Hironori_Washizaki.jpg":R,"../assets/image/photos/Jun_Sun.jpg":B,"../assets/image/photos/Luo Mai.jpg":E,"../assets/image/photos/Marco Canini.jpg":K,"../assets/image/photos/Mohamed WAHIB.jpg":G,"../assets/image/photos/Stefanos Kaxiras.jpg":x,"../assets/image/photos/sun_jun.jpg":F})[`../assets/image/photos/${r}`],self.location).href;return(r,e)=>{const g=T;return s(),c("div",O,[e[7]||(e[7]=a("h1",{class:"title1 font-merri"},"Invited Speakers",-1)),(s(),c(C,null,k(o,(i,h)=>a("div",{key:h,class:"speaker-section"},[a("div",W,[a("div",V,[a("img",{src:n(i.photo),alt:i.name},null,8,$),a("div",q,[a("a",{href:i.personalPage,target:"_blank"},e[0]||(e[0]=[a("img",{class:"icon-item",src:z,alt:""},null,-1)]),8,Y),a("a",{href:i.academicPage,target:"_blank"},e[1]||(e[1]=[a("img",{class:"icon-item",src:J,alt:""},null,-1)]),8,Q)])]),a("div",X,[a("h2",Z,l(i.name),1),a("p",null,[e[2]||(e[2]=a("span",{class:"bold"},"Speech:",-1)),e[3]||(e[3]=d()),a("span",ee,l(i.keynote),1)]),a("p",null,[e[4]||(e[4]=a("span",{class:"bold"},"Abstract:",-1)),e[5]||(e[5]=d()),a("span",ae,l(i.abstract),1)])])]),a("div",ie,[a("p",null,[e[6]||(e[6]=a("span",{class:"bold"},"Bio:",-1)),d(" "+l(i.bio),1)])]),h<o.length-1?(s(),D(g,{key:0})):f("",!0)])),64))])}}});const se=j(ne,[["__scopeId","data-v-425b9843"]]);export{se as default};
